<!--
SPDX-FileCopyrightText: 2026 Colaboradores de apuntes_muicd_uned

SPDX-License-Identifier: CC-BY-4.0
-->

# Aprendizaje Automático II

En esta carpeta se incluyen recursos de apoyo educativo para la asignatura de Aprendizaje Automático II.

## Comunidades

Existen comunidades no oficiales de alumnos y alumni del máster:

- Comunidad [UNED - Aprendizaje Automático II (Máster Datos)](https://t.me/joinchat/VrRO59IZYENjMzNk) en Telegram
- [Carpeta `Aprendizaje Automático II` del Grupo Master Ingenieria y Ciencias de Datos](https://unedo365.sharepoint.com/:f:/s/GrupoMasterIngenieriayCienciasdeDatos/IgAhrQlnu8HdS4tEmOXFoycbAXBtbnuItHrhgTRV8nkc36A) en SharePoint UNED

## Evaluación

| Actividad evaluación | % nota final | % nota mínima |
| - | - | - |
| PEC 1 | 30 | - |
| PEC 2 | 20 | - |
| Exámen | 50 | 45 |

### PEC 1

% sobre la nota final: 30%

### PEC 2

% sobre la nota final: 20%

### Exámen

% sobre la nota final: 50%
Nota mínima para aprobar: 45% (4.5 sobre 10)

Tipo: multiopción
10 preguntas tipo test con 4 posibles respuestas
Preguntas correctas: +1 punto
Pregunta incorrecta: -0.3 puntos

El exámen consta de 10 preguntas tipo test con 4 posibles respuestas, donde cada pregunta correcta suma 1 punto y cada pregunta incorrecta resta 0,3.

Desde el curso 2023/2024 se redujo la duración del exámen a 60 minutos. Anteriormente eran 120 minutos.

## Bibliografía

- Básica
  - JAMES, G., WITTEN, D., HASTIE, T. TIBSHIRANI, R. [An Introduction to Statistical Learning](https://www.statlearning.com/)  
  - HASTIE, Trevor, TIBSHIRANI, Robert, FRIEDMAN, Jerome. [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/). 2.ª ed. New York: Springer, 2009.  
  - LOUPE, Gilles. [Understanding Random Forests: from Theory to Practice](https://arxiv.org/abs/1407.7502), Univ. de Liège  
  - TAYLOR, Courtney. [What Is Bootstrapping in Statistics?](https://www.thoughtco.com/what-is-bootstrapping-in-statistics-3126172). ThoughtCo, 2019  
  - SCHAPIRE, Robert E., FREUND, Yoav. [Boosting: Foundations and Algorithms](https://direct.mit.edu/books/oa-monograph/5342/BoostingFoundations-and-Algorithms)  
  - COOK, Darren. [Practical machine learning with H2O](https://www.oreilly.com/library/view/practical-machine-learning/9781491964590/)  
  - [CatBoost vs. LightGBM vs. XGBoost](https://towardsdatascience.com/catboost-vs-lightgbm-vs-xgboost-c80f40662924/)  
  - M. Mohandes, M. Deriche and S.O. Aliyu. [Classifiers Combination Techniques: A Comprehensive Review](https://ieeexplore.ieee.org/document/8335271)  
  - Informe técnico [Evaluation Metrics for Unsupervised Learning Algorithms](https://doi.org/10.48550/arXiv.1905.05667)  
- Complementaria
  - BREIMAN, Leo [Random Forests](https://doi.org/10.1023/A:1010933404324). luwer Academic Publishers, 2001.
  - DŽEROSKI, S., ŽENKO, B. [Is Combining Classifiers with Stacking Better than Selecting the Best One?](https://doi.org/10.1023/B:MACH.0000015881.36452.6e)  
  - BERZAL, Fernando, PALACIO-NIÑO, Julio-Omar. [Evaluation Metrics for Unsupervised Learning Algorithms](https://www.researchgate.net/publication/333102602_Evaluation_Metrics_for_Unsupervised_Learning_Algorithms). Mayo 2019.
