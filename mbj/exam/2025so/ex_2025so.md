<!--
SPDX-FileCopyrightText: 2026 Colaboradores de apuntes_muicd_uned

SPDX-License-Identifier: CC-BY-4.0
-->

# EX.2025SO

## EX.2025SO.1

### Enunciado EX.2025SO.1

El cociente de las probabilidades (o densidades de probabilidad) a posteriori ($posterior\ odds$) para unas observaciones $y$ es

a) directamente proporcional a $p(y)$

b) independiente de $p(y)$

c) inversamente proporcional a $p(y)$

### Solución EX.2025SO.1

b)

---

## EX.2025SO.2

### Enunciado EX.2025SO.2

Si $p(x)$ es una distribución de probabilidad para la variable aleatoria $x$, una transformación de la variable $x$ a otra variable $y$, $y = f(x)$

a) resulta en una distribución de probabilidad para la variable transformada que depende del determinante de la matriz Jacobiana de la transformación $f^{-1}$

b) es desaconsejable en general porque introduce patologías en la distribución de probabilidad transformada, $p(y)$

c) resulta en una distribución de probabilidad para la variable transformada que es inversamente proporcional a la matriz Jacobiana de la transformación $f$

### Solución EX.2025SO.2

a)

---

## EX.2025SO.3

### Enunciado EX.2025SO.3

Los modelos conjugados se caracterizan por

a) la elección de una definición analítica del prior que hace que la verosimilitud tenga la misma forma algebraica (que el prior); la elección depende de la distribución a posteriori deseada

b) la elección de una definición analítica del prior que hace que la distribución a posteriori de los parámetros pertenezca a la misma familia de distribuciones de probabilidad que la verosimilitud; la elección depende de la verosimilitud

c) la elección de una definición analítica de la verosimilitud que hace que la distribución a posteriori de los parámetros pertenezca a la misma familia de distribuciones de probabilidad que la distribución a priori; la elección depende del prior asumido.

### Solución EX.2025SO.3

b)

---

## EX.2025SO.4

### Enunciado EX.2025SO.4

En el análisis de varianza tradicional, si tenemos datos de varios grupos que creemos generados a partir de distribuciones normales (todas ellas caracterizadas por la misma desviación estándar) y el cociente de la media de la suma de mínimos cuadrados entre grupos (Mean Square Between groups) dividido por la misma media pero interna de cada grupo (Mean Square Within groups) es muy superior a 1, ¿cuál de las siguientes afirmaciones es correcta?

a) dicho análisis de varianza indica que no hay evidencia de que existan diferencias entre las medias muestrales de cada grupo y se obtiene una mejor estimación de la media global con todas las observaciones independientemente del grupo al que pertenezcan

b) dicho análisis de varianza indica que los grupos tienen medias muestrales muy diferentes y es preferible estimar cada media únicamente con los datos del grupo correspondiente

c) Las dos afirmaciones anteriores son compatibles.

### Solución EX.2025SO.4

b)

---

## EX.2025SO.5

### Enunciado EX.2025SO.5

El estudio de la calibración de un parámetro $\theta$ en el contexto Bayesiano analiza

a) diferencias sistemáticas entre el valor esperado de ese parámetro dados los datos ($\hat\theta = E(\theta \mid y)$) y el valor esperado en inferencia si el valor verdadero fuese precisamente $\theta$ (es decir, $p(\hat\theta \mid \theta)$)

b) el cociente entre los valores esperados a priori y a posteriori.

c) diferencias sistemáticas entre el valor esperado a priori (el valor esperado para la distribución de probabilidad a priori) y el valor esperado de la distribución marginal a posteriori

### Solución EX.2025SO.5

a)

---

## EX.2025SO.6

### Enunciado EX.2025SO.6

En el caso de que no dispongamos de expresiones analíticas para las distribuciones a posteriori de los parámetros $\theta$ de un modelo (o que el número de parámetros sea tan elevado que no sea posible marginalizar), podemos estimar la exactitud predictiva ($predictive\ accuracy$) de un modelo recurriendo a

a) sustituir la distribución a posteriori por el producto de la verosimilitud y la distribución marginal a posteriori.

b) nada; no se puede calcular ni estimar o aproximar.

c) la estimación

$$
\sum_{i=1}^{n} \log \left( \frac{1}{S} \sum_{s=1}^{S} p(y_i \mid \theta^s) \right)
$$

basada en un conjunto de $S$ muestras de dicha distribución a posteriori.

### Solución EX.2025SO.6

c)

---

## EX.2025SO.7

### Enunciado EX.2025SO.7

La desviación o $deviance$ en inglés se define como

a) el valor esperado del logaritmo de la densidad predictiva

b) -2 veces el logaritmo de la densidad predictiva dado un único estimador (la estimación puntual) de los parámetros del modelo

c) -2 veces el valor esperado del logaritmo de la densidad predictiva

### Solución EX.2025SO.7

b)

---

## EX.2025SO.8

### Enunciado EX.2025SO.8

En el caso de que tengamos una muestra infinita de datos para estimar los parámetros de un modelo, el máximo de la distribución a posteriori del logaritmo de la densidad predictiva...

a) está distribuido según una variable $\chi^2$ con $\frac{k}{2}$ grados de libertad

b) coincide con la estimación máximo verosímil y su media está $\frac{k}{2}$ por encima

c) coincide con la estimación máximo verosímil y su media está $\frac{k}{2}$ por debajo

### Solución EX.2025SO.8

c)

---

## EX.2025SO.9

### Enunciado EX.2025SO.9

El hecho de que la inferencia en un modelo Bayesiano se vea constreñida por la utilización de distribuciones a priori implica

a) que no tiene sentido utilizar el número efectivo de parámetros del modelo como medida de su complejidad.

b) que el número efectivo de parámetros puede ser mayor que el número de parámetros del modelo

c) que el número efectivo de parámetros puede ser menor que el número de parámetros del modelo

### Solución EX.2025SO.9

c)

---

## EX.2025SO.10

### Enunciado EX.2025SO.10

El factor de Bayes es

a) el cociente de probabilidades a posteriori de dos modelos que queremos comparar

b) el cociente de verosimilitudes marginales para dos modelos que queremos comparar

c) el cociente de probabilidades a priori de dos modelos que queremos comparar

### Solución EX.2025SO.10

b)

---
