<!--
SPDX-FileCopyrightText: 2026 Colaboradores de apuntes_muicd_uned

SPDX-License-Identifier: CC-BY-4.0
-->

# EX.2023J2

## EX.2023J2.1

### Enunciado EX.2023J2.1

Desde una perspectiva estadística, la verosimilitud (*likelihood*) se interpreta como una función de densidad o masa de probabilidad de:

a) Los parámetros que definen el modelo estadístico.
b) Las dos opciones anteriores son correctas.
c) Los datos u observaciones que han sido registrados.

### Solución EX.2023J2.1

c)

## EX.2023J2.2

### Enunciado EX.2023J2.2

La relación entre el cociente de probabilidades a posteriori (*posterior odds*) y el cociente de verosimilitudes es:

a) De proporcionalidad directa entre ambos términos.
b) De independencia absoluta; uno no afecta al otro.
c) De proporcionalidad inversa entre el cociente posterior y el de verosimilitud.

### Solución EX.2023J2.2

a)

## EX.2023J2.3

### Enunciado EX.2023J2.3

De acuerdo con la ley de la varianza total, para dos variables aleatorias con distribución conjunta $p(u, v)$, la varianza de $u$ se descompone como:

a) La suma de la esperanza de la varianza condicional $E(var(u \mid v))$ y la varianza de la esperanza condicional $var(E(u \mid v))$.
b) Ninguna de las expresiones propuestas representa correctamente esta descomposición.
c) El producto entre la media de la varianza condicional y la varianza de la media condicionada.

### Solución EX.2023J2.3

a)

## EX.2023J2.4

### Enunciado EX.2023J2.4

En un modelo normal jerárquico con un prior uniforme para el hiperparámetro $\mu$, su distribución posterior condicionada a la varianza $\tau$ y a los datos $y$ es:

a) Una normal cuya media es el promedio de las medias grupales ponderado por la suma de la varianza intragrupo $\sigma_j^2$ y la varianza entre grupos $\tau^2$.
b) Una normal donde la varianza total se obtiene sumando linealmente las varianzas internas y externas de los grupos.
c) Una normal cuya media es el promedio ponderado de las medias de cada grupo, usando como peso el inverso de la suma de las varianzas $\sigma_j^2$ y $\tau^2$.

### Solución EX.2023J2.4

c)

## EX.2023J2.5

### Enunciado EX.2023J2.5

¿Cómo se define la distribución posterior marginal de los hiperparámetros en el contexto de un modelo normal jerárquico?

a) Como el producto entre la distribución a priori de los hiperparámetros y un conjunto de densidades normales cuya varianza combina la variabilidad intragrupo y la varianza entre grupos.
b) Únicamente como el producto de las funciones de verosimilitud calculadas de forma independiente para cada grupo.
c) Como el resultado de multiplicar la distribución marginal posterior de las medias grupales por el prior de los hiperparámetros.

### Solución EX.2023J2.5

a)

## EX.2023J2.6

### Enunciado EX.2023J2.6

En relación a las métricas de precisión predictiva como $elpd$ (log-densidad predictiva esperada) y $elppd$:

a) Resulta imposible calcularlas con exactitud dado que la verdadera distribución generadora de datos $p^*$ es desconocida.
b) Ninguna de las afirmaciones presentadas describe correctamente la naturaleza de estos cálculos.
c) Se consideran cálculos estándar que se obtienen de forma directa para validar cualquier modelo.

### Solución EX.2023J2.6

b)

## EX.2023J2.7

### Enunciado EX.2023J2.7

El propósito fundamental de emplear la validación cruzada como técnica de evaluación es:

a) Estimar de forma indirecta el número efectivo de parámetros que componen la complejidad del modelo.
b) Minimizar el sesgo optimista que surge al evaluar el rendimiento del modelo utilizando los mismos datos empleados en su entrenamiento.
c) Evaluar modelos de un solo nivel, ya que su aplicación en estructuras jerárquicas bayesianas es inviable.

### Solución EX.2023J2.7

b)

## EX.2023J2.8

### Enunciado EX.2023J2.8

Una de las características principales del Criterio de Información Bayesiano (BIC) es que:

a) Su meta principal es la evaluación precisa de la densidad predictiva del modelo.
b) Aplica una penalización por sobreajuste que no varía en función del tamaño de la muestra utilizada.
c) Su justificación teórica se basa en la estimación de la probabilidad marginal de los datos observados $p(y)$.

### Solución EX.2023J2.8

c)

## EX.2023J2.9

### Enunciado EX.2023J2.9

La técnica de validación cruzada "dejar uno fuera" (LOO-CV) para estimar la capacidad predictiva consiste en:

a) Sumar los logaritmos de la densidad predictiva de cada dato individual, calculados con un modelo entrenado con el resto de la muestra; el sesgo se reduce notablemente al aumentar $N$.
b) Evaluar la densidad predictiva dividiendo la muestra en diez bloques independientes y rotando el entrenamiento entre ellos.
c) Calcular la suma de logaritmos de la densidad predictiva para cada punto usando el modelo entrenado con todos los datos; se considera un método sin sesgo.

### Solución EX.2023J2.9

a)

## EX.2023J2.10

### Enunciado EX.2023J2.10

El Factor de Bayes se define técnicamente como:

a) La razón entre las probabilidades a posteriori de dos modelos en competencia.
b) La razón entre las verosimilitudes marginales (evidencias) de los dos modelos que se pretenden comparar.
c) El cociente entre las distribuciones de probabilidad a priori definidas para cada modelo.

### Solución EX.2023J2.10

b)
