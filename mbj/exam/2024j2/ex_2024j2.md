# EX.2024J2

## EX.2024J2.1

### Enunciado EX.2024J2.1

En inferencia estadística, la verosimilitud (*likelihood*) se define como una función de probabilidad referida a:

a) El conjunto de parámetros desconocidos del modelo.
b) Las otras dos opciones son correctas.
c) El conjunto de datos u observaciones registradas.

### Solución EX.2024J2.1

c)

---

## EX.2024J2.2

### Enunciado EX.2024J2.2

La función de probabilidad conjunta para tres variables $p(u, v, w)$:

a) Admite de forma exclusiva la descomposición $p(u \mid v, w) \cdot p(v \mid w) \cdot p(w)$.
b) Puede ser factorizada utilizando cualquiera de las secuencias de las otras opciones (así como otras combinaciones).
c) Admite de forma exclusiva la descomposición $p(w \mid v, u) \cdot p(v \mid u) \cdot p(u)$.

### Solución EX.2024J2.2

b)

---

## EX.2024J2.3

### Enunciado EX.2024J2.3

Si se introduce una distribución a priori impropia en el análisis bayesiano:

a) La distribución a posteriori será, por definición, siempre propia.
b) El resultado será necesariamente una distribución a posteriori impropia.
c) Ninguna de las afirmaciones anteriores describe una consecuencia inevitable.

### Solución EX.2024J2.3

c)

## EX.2024J2.4

### Enunciado EX.2024J2.4

Bajo un modelo normal jerárquico con un prior uniforme para el nivel superior $p(\mu \mid \tau)$, la distribución posterior del hiperparámetro $\mu$ es:

a) Una normal con una varianza equivalente a la suma de la varianza entre grupos $\tau^2$ y las varianzas internas $\sigma_j^2$.
b) Una normal cuya media se calcula como el promedio de las medias grupales ponderado por el inverso de la suma $(\sigma_j^2 + \tau^2)$.
c) Una normal cuya media se calcula como el promedio de las medias grupales ponderado directamente por la suma $(\sigma_j^2 + \tau^2)$.

### Solución EX.2024J2.4

b)

## EX.2024J2.5

### Enunciado EX.2024J2.5

Respecto al valor esperado del logaritmo de la densidad predictiva para observaciones futuras:

a) Se determina multiplicando los logaritmos de cada punto, asumiendo independencia estadística.
b) Se calcula sumando los logaritmos de cada punto, asumiendo independencia estadística de forma estricta.
c) Se estima analizando los puntos individualmente (enfoque *pointwise*) y sumando sus logaritmos ($elppd$).

### Solución EX.2024J2.5

c)

## EX.2024J2.6

### Enunciado EX.2024J2.6

Si no es posible obtener una solución analítica para la posterior de $\theta$ debido a su complejidad, la precisión predictiva se puede estimar mediante:

a) No existe procedimiento técnico para realizar dicha estimación en ausencia de fórmulas analíticas.
b) La expresión $\sum_{i=1}^{n} \log \left( \frac{1}{S} \sum_{s=1}^{S} p(y_i \mid \theta^s) \right)$, utilizando un muestreo de $S$ valores de la posterior.
c) El reemplazo de la posterior por el producto de la verosimilitud y la distribución marginal posterior.

### Solución EX.2024J2.6

b)

## EX.2024J2.7

### Enunciado EX.2024J2.7

El Criterio de Información de Akaike (AIC) se establece formalmente como:

a) -2 veces el logaritmo de la densidad predictiva evaluada en la moda posterior, sumando una penalización de $2k$.
b) -2 veces el logaritmo de la densidad predictiva evaluada en la moda posterior, sumando una penalización de $k$.
c) -2 veces el logaritmo de la densidad evaluada en el estimador de máxima verosimilitud, con un ajuste por sobreajuste igual al doble del número de parámetros.

### Solución EX.2024J2.7

c)

## EX.2024J2.8

### Enunciado EX.2024J2.8

¿Cómo se define el Criterio de Información de Watanabe-Akaike (WAIC)?

a) Como -2 veces el logaritmo de la densidad en la media posterior, con un ajuste que puede tomar valores negativos.
b) Como -2 veces la estimación del logaritmo de la densidad predictiva *pointwise* ($lppd$), corregida mediante términos de penalización análogos a la validación cruzada.
c) Como el valor del logaritmo de la densidad en la moda posterior, ajustado por una penalización de $2k$.

### Solución EX.2024J2.8

b)

## EX.2024J2.9

### Enunciado EX.2024J2.9

El uso de distribuciones a priori en la inferencia bayesiana actúa como una restricción que conlleva:

a) Que la cantidad efectiva de parámetros pueda superar el número nominal de parámetros del modelo.
b) Que el número efectivo de parámetros sea potencialmente menor que el número de parámetros definidos.
c) Que el concepto de parámetros efectivos carezca de sentido para evaluar la complejidad del modelo.

### Solución EX.2024J2.9

b)

## EX.2024J2.10

### Enunciado EX.2024J2.10

La prueba de que el algoritmo de Metropolis converge a la distribución posterior objetivo se basa en:

a) Demostrar que las probabilidades de transición entre dos estados cualesquiera de los parámetros son simétricas por naturaleza.
b) Demostrar que la ratio de probabilidades posteriores entre dos estados sucesivos es independiente de la distribución de propuesta elegida.
c) Confirmar que distintas cadenas de Markov iniciadas aleatoriamente convergen hacia el mismo valor numérico.

### Solución EX.2024J2.10

b)
